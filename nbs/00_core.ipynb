{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import random\n",
    "from io import StringIO\n",
    "from typing import Collection, Dict, Optional\n",
    "\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "Connection = psycopg2.extensions.connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def _get_connection_arguments(server: str,\n",
    "                              dotenv_path: str = '.env',\n",
    "                              **conn_kwargs) -> Dict[str,str]:\n",
    "    \"Get connection arguments for server from .env file and conn_kwargs.\"\n",
    "    load_dotenv(dotenv_path)\n",
    "    variables = ('host', 'port', 'database', 'user', 'password')\n",
    "    params = {variable: os.getenv(f'postgres_{variable}_{server}'.upper())\n",
    "              for variable in variables}\n",
    "    params.update(conn_kwargs)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_connection(server: str,\n",
    "                      dotenv_path: str = '.env',\n",
    "                      **conn_kwargs) -> Connection:\n",
    "    \"Create psycopg2 connection to server from .env file and conn_kwargs.\"\n",
    "    conn_args = _get_connection_arguments(server, dotenv_path, **conn_kwargs)\n",
    "    return psycopg2.connect(**conn_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create a connection by using the server name and specifying the path to the `.env` file.\n",
    "\n",
    "```\n",
    "con = create_connection('server', 'path/to/.env')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def append_dataframe_to_table(conn: Connection,\n",
    "                              table: str,\n",
    "                              df: pd.DataFrame) -> None:\n",
    "    \"Append a dataframe to an existing postgresql table.\"\n",
    "    with conn.cursor() as cur:\n",
    "        output = StringIO()\n",
    "        df.to_csv(output, sep='\\t', header=False, index=False)\n",
    "        output.seek(0)\n",
    "        cur.copy_from(output, table, null='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be used with a connection context manager to execute the append in a transaction, like so:\n",
    "\n",
    "```\n",
    "with create_connection('server', 'path/to/.env') as conn:\n",
    "    append_dataframe_to_table(conn, 'table_name', df)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the append fails, a rollback is performed, else it is commited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def update_table_from_df(conn: Connection,\n",
    "                         table: str,\n",
    "                         df: pd.DataFrame,\n",
    "                         join_cols: Collection[str],\n",
    "                         update_cols: Optional[Collection[str]] = None,\n",
    "                         extra_where: Optional[str] = None):\n",
    "    \"\"\"Updates a postgresql table using the contents of a dataframe.\n",
    "\n",
    "    If update_cols is None (the default) join_cols are used in the where\n",
    "    statement of the update and the remaining columns are updated,\n",
    "    otherwise only update_cols are updated.\n",
    "\n",
    "    extra_where is placed at the start of the where statement.\n",
    "    \"\"\"\n",
    "    if update_cols is None:\n",
    "        update_cols = df.columns.drop(join_cols)\n",
    "    temp_table = f'temp_replacements_{random.randint(1, 1000):04}'\n",
    "    create_query = f\"\"\"\n",
    "        CREATE TEMP TABLE {temp_table}\n",
    "        AS\n",
    "        SELECT {', '.join(df.columns)}\n",
    "        FROM {table}\n",
    "        LIMIT 0\n",
    "    \"\"\"\n",
    "    def _create_equals_statements(cols, join_str, left_prefix='old_table.'):\n",
    "        statements = [f'{left_prefix}{col} = new_table.{col}' for col in cols]\n",
    "        return join_str.join(statements)\n",
    "    set_statement = _create_equals_statements(update_cols, join_str=',\\n\\t', left_prefix='')\n",
    "    where_statement = _create_equals_statements(join_cols, join_str='\\n\\tAND ')\n",
    "    if extra_where is not None:\n",
    "        where_statement = extra_where + '\\n\\tAND ' + where_statement\n",
    "    update_query = f\"\"\"\n",
    "        UPDATE {table} AS old_table\n",
    "        SET {set_statement}\n",
    "        FROM {temp_table} new_table\n",
    "        WHERE {where_statement}\n",
    "    \"\"\"\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(create_query)\n",
    "        append_dataframe_to_table(conn, temp_table, df)\n",
    "        cur.execute(update_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be performed as well within a conext manager\n",
    "\n",
    "```\n",
    "with create_connection('server', 'path/to/.env') as conn:\n",
    "    update_table_from_df(conn, 'table_name', df, join_cols='x')\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
